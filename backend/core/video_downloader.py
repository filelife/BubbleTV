import requests
import re
import time
import os
import http.cookiejar
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import yt_dlp
from .video_scraper import VideoScraper
from .video_transcoder import VideoTranscoder

class VideoParser:
    def __init__(self):
        self.platform_patterns = {
            'bilibili': [
                r'b23\.tv/([a-zA-Z0-9]+)',
                r'bilibili\.com/video/([a-zA-Z0-9]+)',
                r'bilibili\.com/video/BV([a-zA-Z0-9]+)',
                r'bilibili\.com/bangumi/play/ep([0-9]+)'
            ],
            'douyin': [
                r'v\.douyin\.com/([a-zA-Z0-9]+)',
                r'douyin\.com/video/([0-9]+)'
            ],
            'toutiao': [
                r'm\.toutiao\.com/is/([a-zA-Z0-9]+)',
                r'toutiao\.com/video/([0-9]+)'
            ]
        }
        self.scraper = VideoScraper()
    
    def detect_platform(self, url):
        for platform, patterns in self.platform_patterns.items():
            for pattern in patterns:
                if re.search(pattern, url):
                    return platform
        return None
    
    def detect_video_type(self, url, platform):
        if platform == 'bilibili':
            return self._detect_bilibili_type(url)
        elif platform == 'douyin':
            return self._detect_douyin_type(url)
        elif platform == 'toutiao':
            return self._detect_toutiao_type(url)
        return 'çŸ­è§†é¢‘'
    
    def _detect_bilibili_type(self, url):
        if re.search(r'bilibili\.com/video/BV', url):
            return 'çŸ­è§†é¢‘'
        elif re.search(r'bilibili\.com/medialist', url):
            return 'å½±è§†å‰§'
        elif re.search(r'bilibili\.com/bangumi', url):
            return 'ç•ªå‰§'
        return 'çŸ­è§†é¢‘'
    
    def _detect_douyin_type(self, url):
        return 'çŸ­è§†é¢‘'
    
    def _detect_toutiao_type(self, url):
        return 'çŸ­è§†é¢‘'
    
    def parse_video_info(self, url):
        url = self._clean_url(url)
        
        if not self._is_valid_url(url):
            raise ValueError('æ— æ•ˆçš„è§†é¢‘é“¾æ¥æ ¼å¼')
        
        platform = self.detect_platform(url)
        if not platform:
            raise ValueError('ä¸æ”¯æŒçš„è§†é¢‘å¹³å°')
        
        try:
            return self.scraper.scrape_video(url)
        except Exception as e:
            raise Exception(f'è§£æè§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}')
    
    def _clean_url(self, url):
        url = url.strip()
        url_pattern = r'(https?://[^\s\]\)`\'"]+)'
        match = re.search(url_pattern, url)
        if match:
            return match.group(1)
        return url
    
    def _is_valid_url(self, url):
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except:
            return False
    
    def _parse_bilibili(self, url):
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        title = soup.find('title')
        if title:
            title = title.string.strip()
        else:
            title = 'æœªçŸ¥æ ‡é¢˜'
        
        return {
            'title': title,
            'platform': 'bilibili',
            'url': url,
            'video_type': self.detect_video_type(url, 'bilibili')
        }
    
    def _parse_douyin(self, url):
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        title = soup.find('title')
        if title:
            title = title.string.strip()
        else:
            title = 'æœªçŸ¥æ ‡é¢˜'
        
        return {
            'title': title,
            'platform': 'douyin',
            'url': url,
            'video_type': self.detect_video_type(url, 'douyin')
        }
    
    def _parse_toutiao(self, url):
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        title = soup.find('title')
        if title:
            title = title.string.strip()
        else:
            title = 'æœªçŸ¥æ ‡é¢˜'
        
        return {
            'title': title,
            'platform': 'toutiao',
            'url': url,
            'video_type': self.detect_video_type(url, 'toutiao')
        }


class VideoDownloader:
    def __init__(self, redis_manager):
        self.redis = redis_manager
        self.parser = VideoParser()
        self.scraper = VideoScraper()
        self.transcoder = VideoTranscoder(redis_manager)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
    
    def _log(self, task_id, message):
        """è®°å½•ä»»åŠ¡æ—¥å¿—"""
        if task_id:
            self.redis.add_task_log(task_id, message)
            print(f"[{task_id[:8]}] {message}")
        else:
            print(f"[LOG] {message}")
    
    def _format_speed(self, speed_bytes):
        if speed_bytes < 1024:
            return f'{speed_bytes:.2f} B/s'
        elif speed_bytes < 1024 * 1024:
            return f'{speed_bytes / 1024:.2f} KB/s'
        elif speed_bytes < 1024 * 1024 * 1024:
            return f'{speed_bytes / (1024 * 1024):.2f} MB/s'
        else:
            return f'{speed_bytes / (1024 * 1024 * 1024):.2f} GB/s'
    
    def _download_douyin_with_ytdlp(self, url, task_id, output_path, cookie_data=None):
        try:
            print("=" * 60)
            print(f"ğŸ“¥ å¼€å§‹yt-dlpä¸‹è½½æŠ–éŸ³è§†é¢‘")
            print("=" * 60)
            
            # é˜¶æ®µ1: å‡†å¤‡ä¸‹è½½
            print(f"ğŸ“ é˜¶æ®µ1: å‡†å¤‡ä¸‹è½½å‚æ•°")
            try:
                safe_filename = self._get_safe_filename('douyin_video')
                temp_file = os.path.join(os.path.dirname(output_path), f"{safe_filename}.mp4")
                print(f"âœ… ä¸´æ—¶æ–‡ä»¶è·¯å¾„: {temp_file}")
            except Exception as e:
                print(f"âŒ é˜¶æ®µ1å¤±è´¥: å‡†å¤‡å‚æ•°é”™è¯¯")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                raise Exception(f'å‡†å¤‡ä¸‹è½½å‚æ•°å¤±è´¥: {str(e)}')
            
            # é˜¶æ®µ2: é…ç½®yt-dlp
            print(f"âš™ï¸  é˜¶æ®µ2: é…ç½®yt-dlpå‚æ•°")
            try:
                ydl_opts = {
                    'format': 'best[ext=mp4]/best',
                    'outtmpl': temp_file,
                    'quiet': False,
                    'no_warnings': False,
                    'progress_hooks': [lambda d: self._ytdlp_progress_hook(d, task_id)],
                    'user_agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1',
                    'nocheckcertificate': True,
                    'ignoreerrors': False,
                    'extract_flat': False,
                }
                
                # å¦‚æœæœ‰Cookieï¼Œæ·»åŠ åˆ°yt-dlpé…ç½®
                if cookie_data and 'cookie' in cookie_data:
                    print(f"âœ… ä½¿ç”¨Cookieè¿›è¡Œä¸‹è½½")
                    # å°†Cookieå­—ç¬¦ä¸²è½¬æ¢ä¸ºNetscapeæ ¼å¼å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                    import tempfile
                    cookie_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
                    
                    # å†™å…¥Netscapeæ ¼å¼å¤´éƒ¨
                    cookie_file.write("# Netscape HTTP Cookie File\n")
                    cookie_file.write("# This is a generated file! Do not edit.\n\n")
                    
                    # è§£æCookieå­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸ºNetscapeæ ¼å¼
                    cookies = cookie_data['cookie'].split(';')
                    for cookie in cookies:
                        cookie = cookie.strip()
                        if '=' in cookie:
                            name, value = cookie.split('=', 1)
                            # Netscapeæ ¼å¼: domain \t flag \t path \t secure \t expiration \t name \t value
                            # domainè®¾ç½®ä¸º.douyin.comï¼Œflagä¸ºTRUEè¡¨ç¤ºå­åŸŸåä¹Ÿæœ‰æ•ˆ
                            cookie_file.write(f".douyin.com\tTRUE\t/\tFALSE\t9999999999\t{name.strip()}\t{value.strip()}\n")
                    
                    cookie_file.close()
                    ydl_opts['cookiefile'] = cookie_file.name
                    print(f"âœ… Cookieå·²ä¿å­˜åˆ°Netscapeæ ¼å¼æ–‡ä»¶: {cookie_file.name}")
                else:
                    print(f"âš ï¸  æœªæä¾›Cookieï¼Œå°è¯•æ— Cookieä¸‹è½½")
                
                print(f"âœ… yt-dlpé…ç½®å®Œæˆ")
            except Exception as e:
                print(f"âŒ é˜¶æ®µ2å¤±è´¥: é…ç½®yt-dlpé”™è¯¯")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                raise Exception(f'é…ç½®yt-dlpå¤±è´¥: {str(e)}')
            
            # é˜¶æ®µ3: æ‰§è¡Œä¸‹è½½
            print(f"ğŸ“¥ é˜¶æ®µ3: æ‰§è¡Œyt-dlpä¸‹è½½")
            try:
                import yt_dlp
                print(f"âœ… yt-dlpå¯¼å…¥æˆåŠŸ")
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    print(f"ğŸš€ å¼€å§‹ä¸‹è½½: {url}")
                    try:
                        ydl.download([url])
                        print(f"âœ… yt-dlpä¸‹è½½å®Œæˆ")
                    except Exception as download_error:
                        print(f"âŒ é˜¶æ®µ3å¤±è´¥: yt-dlpä¸‹è½½é”™è¯¯")
                        print(f"   é”™è¯¯è¯¦æƒ…: {str(download_error)}")
                        print(f"   é”™è¯¯ç±»å‹: {type(download_error).__name__}")
                        import traceback
                        traceback.print_exc()
                        raise Exception(f'yt-dlpä¸‹è½½å¤±è´¥: {str(download_error)}')
            except ImportError as ie:
                print(f"âŒ é˜¶æ®µ3å¤±è´¥: yt-dlpæœªå®‰è£…")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(ie)}")
                raise Exception(f'yt-dlpæœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½æŠ–éŸ³è§†é¢‘')
            except Exception as e:
                print(f"âŒ é˜¶æ®µ3å¤±è´¥: ä¸‹è½½è¿‡ç¨‹é”™è¯¯")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                import traceback
                traceback.print_exc()
                raise
            
            # é˜¶æ®µ4: æ£€æŸ¥ä¸‹è½½ç»“æœ
            print(f"ğŸ” é˜¶æ®µ4: æ£€æŸ¥ä¸‹è½½ç»“æœ")
            try:
                if os.path.exists(temp_file):
                    file_size = os.path.getsize(temp_file)
                    print(f"âœ… æ–‡ä»¶å·²åˆ›å»º: {temp_file}")
                    print(f"   æ–‡ä»¶å¤§å°: {file_size} bytes ({file_size / 1024 / 1024:.2f} MB)")
                    
                    if file_size > 0:
                        print(f"âœ… æ–‡ä»¶å¤§å°æ­£å¸¸ï¼Œå‡†å¤‡è½¬ç ")
                    else:
                        print(f"âŒ æ–‡ä»¶å¤§å°ä¸º0ï¼Œä¸‹è½½å¤±è´¥")
                        # æ·»åŠ åŸå§‹URLåˆ°é”™è¯¯ä¿¡æ¯
                        error_msg = f'ä¸‹è½½å¤±è´¥: ä¸‹è½½çš„æ–‡ä»¶å¤§å°ä¸º0ï¼Œå¯èƒ½æ˜¯ç½‘é¡µæœªæ­£ç¡®è§£æå‡ºè§†é¢‘ä¸‹è½½åœ°å€\n\nåŸå§‹URL: {url}'
                        self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                        return False, error_msg
                else:
                    print(f"âŒ æ–‡ä»¶æœªåˆ›å»º: {temp_file}")
                    # æ·»åŠ åŸå§‹URLåˆ°é”™è¯¯ä¿¡æ¯
                    error_msg = f'ä¸‹è½½å¤±è´¥: è§†é¢‘æ–‡ä»¶æœªåˆ›å»ºï¼Œå¯èƒ½æ˜¯ç½‘é¡µæœªè§£æå‡ºè§†é¢‘ä¸‹è½½åœ°å€æˆ–ä¸‹è½½è¿‡ç¨‹ä¸­æ–­\n\nåŸå§‹URL: {url}'
                    self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                    return False, error_msg
            except Exception as e:
                print(f"âŒ é˜¶æ®µ4å¤±è´¥: æ£€æŸ¥æ–‡ä»¶é”™è¯¯")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                raise Exception(f'æ£€æŸ¥ä¸‹è½½ç»“æœå¤±è´¥: {str(e)}')
            
            # é˜¶æ®µ5: è½¬ç ä¸ºmovæ ¼å¼
            print(f"ğŸ¬ é˜¶æ®µ5: è½¬ç ä¸ºmovæ ¼å¼")
            try:
                self.redis.update_task_status(task_id, 'transcoding', progress=0)
                print(f"âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: transcoding")
                
                success, message = self.transcoder.transcode_video(temp_file, output_path, task_id)
                
                if success:
                    print(f"âœ… è½¬ç æˆåŠŸ: {output_path}")
                    os.remove(temp_file)
                    print(f"âœ… ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤: {temp_file}")
                    self.redis.update_task_status(task_id, 'completed', progress=100, save_path=output_path)
                    print(f"âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: completed")
                    print("=" * 60)
                    print(f"âœ… ä¸‹è½½ä»»åŠ¡å®Œæˆ")
                    print("=" * 60)
                    return True, 'ä¸‹è½½æˆåŠŸ'
                else:
                    print(f"âŒ é˜¶æ®µ5å¤±è´¥: è½¬ç å¤±è´¥")
                    print(f"   é”™è¯¯è¯¦æƒ…: {message}")
                    # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
                    error_msg = f'è½¬ç å¤±è´¥: {message}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                    self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                    return False, error_msg
            except Exception as e:
                print(f"âŒ é˜¶æ®µ5å¤±è´¥: è½¬ç è¿‡ç¨‹é”™è¯¯")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                import traceback
                traceback.print_exc()
                # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
                error_msg = f'è½¬ç å¤±è´¥: {str(e)}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                return False, error_msg
                
        except Exception as e:
            print("=" * 60)
            print(f"âŒ ä¸‹è½½ä»»åŠ¡å¤±è´¥")
            print(f"   é”™è¯¯é˜¶æ®µ: æœªçŸ¥")
            print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
            print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            print("=" * 60)
            # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
            error_msg = f'ä¸‹è½½å¤±è´¥: {str(e)}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
            self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
            return False, error_msg
    
    def _download_douyin_manual(self, url, task_id, output_path):
        """æ‰‹åŠ¨ä¸‹è½½æŠ–éŸ³è§†é¢‘ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            print(f'Downloading douyin video with manual method: {url}')
            
            video_info = self.parser.parse_video_info(url)
            video_url = video_info.get('video_url')
            
            if not video_url:
                raise Exception('æ— æ³•è·å–è§†é¢‘ä¸‹è½½é“¾æ¥')
            
            print(f'Video URL: {video_url[:100]}...')
            
            headers = self.headers.copy()
            headers['Referer'] = 'https://www.douyin.com'
            headers['Origin'] = 'https://www.douyin.com'
            
            response = requests.get(video_url, headers=headers, stream=True, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded_size = 0
            start_time = time.time()
            last_update_time = start_time
            
            safe_filename = self._get_safe_filename(video_info.get('title', 'video'))
            temp_file = os.path.join(os.path.dirname(output_path), f"{safe_filename}.mp4")
            
            print(f'Saving to: {temp_file}')
            
            with open(temp_file, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        current_time = time.time()
                        if current_time - last_update_time >= 1:
                            elapsed_time = current_time - start_time
                            if elapsed_time > 0:
                                speed = downloaded_size / elapsed_time
                                speed_str = self._format_speed(speed)
                                self.redis.update_task_download_speed(task_id, speed_str)
                            last_update_time = current_time
                        if total_size > 0:
                            progress = int(downloaded_size / total_size * 100)
                            self.redis.update_task_status(task_id, 'downloading', progress=progress)
            
            if os.path.exists(temp_file):
                self.redis.update_task_status(task_id, 'transcoding', progress=0)
                success, message = self.transcoder.transcode_video(temp_file, output_path, task_id)
                
                if success:
                    os.remove(temp_file)
                    self.redis.update_task_status(task_id, 'completed', progress=100, save_path=output_path)
                    return True, 'ä¸‹è½½æˆåŠŸ'
                else:
                    # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
                    error_msg = f'è½¬ç å¤±è´¥: {message}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                    self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                    return False, error_msg
            else:
                # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
                error_msg = f'ä¸‹è½½å¤±è´¥: è§†é¢‘æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½æ˜¯ç½‘é¡µæœªè§£æå‡ºè§†é¢‘ä¸‹è½½åœ°å€\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                return False, error_msg
                
        except Exception as e:
            print(f'Error downloading douyin video: {e}')
            import traceback
            traceback.print_exc()
            # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
            error_msg = f'ä¸‹è½½å¤±è´¥: {str(e)}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
            self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
            return False, error_msg
    
    def _get_safe_filename(self, title):
        import re
        import hashlib
        
        title = re.sub(r'[^\w\s\-\.#]', '', title)
        title = re.sub(r'[\s]+', '_', title.strip())
        
        max_filename_length = 80
        max_path_length = 500
        
        if len(title) > max_filename_length:
            title_hash = hashlib.md5(title.encode()).hexdigest()[:6]
            title = f"{title[:max_filename_length-15]}_{title_hash}"
        
        return title
    
    def _ytdlp_progress_hook(self, d, task_id):
        if d['status'] == 'downloading':
            if 'total_bytes' in d and 'downloaded_bytes' in d:
                progress = int(d['downloaded_bytes'] / d['total_bytes'] * 100)
                self.redis.update_task_status(task_id, 'downloading', progress=progress)
                
                if 'speed' in d:
                    speed_str = self._format_speed(d['speed'])
                    self.redis.update_task_download_speed(task_id, speed_str)
        elif d['status'] == 'finished':
            print(f'Download finished for task {task_id}')
    
    def _parse_cookie_string(self, cookie_str):
        """è§£æCookieå­—ç¬¦ä¸²ä¸ºyt-dlpå¯ç”¨çš„æ ¼å¼"""
        if not cookie_str:
            return None
        
        # yt-dlpå¯ä»¥ç›´æ¥æ¥å—Cookieå­—ç¬¦ä¸²
        return cookie_str
    
    def download_video(self, url, task_id, storage_path):
        try:
            self._log(task_id, "========== å¼€å§‹ä¸‹è½½ä»»åŠ¡ ==========")
            self._log(task_id, f"URL: {url}")
            self._log(task_id, f"å­˜å‚¨è·¯å¾„: {storage_path}")
            
            import os
            
            # é˜¶æ®µ1: æ£€æµ‹å¹³å°
            self._log(task_id, "é˜¶æ®µ1: æ£€æµ‹è§†é¢‘å¹³å°")
            try:
                if 'douyin.com' in url or 'v.douyin.com' in url:
                    platform = 'douyin'
                elif 'bilibili.com' in url:
                    platform = 'bilibili'
                elif 'toutiao.com' in url:
                    platform = 'toutiao'
                else:
                    platform = 'unknown'
                self._log(task_id, f"âœ… å¹³å°æ£€æµ‹å®Œæˆ: {platform}")
            except Exception as e:
                self._log(task_id, f"âŒ é˜¶æ®µ1å¤±è´¥: å¹³å°æ£€æµ‹é”™è¯¯ - {str(e)}")
                raise Exception(f'å¹³å°æ£€æµ‹å¤±è´¥: {str(e)}')
            
            # æŠ–éŸ³å¹³å°ç›´æ¥ä½¿ç”¨yt-dlpä¸‹è½½ï¼Œä¸ç»è¿‡parser
            if platform == 'douyin':
                self._log(task_id, "ğŸ“± æ£€æµ‹åˆ°æŠ–éŸ³å¹³å°ï¼Œä½¿ç”¨yt-dlpç›´æ¥ä¸‹è½½")
                
                # é˜¶æ®µ2: åˆ›å»ºè¾“å‡ºç›®å½•
                self._log(task_id, "é˜¶æ®µ2: åˆ›å»ºè¾“å‡ºç›®å½•")
                try:
                    safe_title = self._get_safe_filename('douyin_video')
                    video_dir = os.path.join(storage_path, platform, safe_title)
                    os.makedirs(video_dir, exist_ok=True)
                    self._log(task_id, f"âœ… ç›®å½•åˆ›å»ºæˆåŠŸ: {video_dir}")
                except Exception as e:
                    self._log(task_id, f"âŒ é˜¶æ®µ2å¤±è´¥: ç›®å½•åˆ›å»ºé”™è¯¯ - {str(e)}")
                    raise Exception(f'ç›®å½•åˆ›å»ºå¤±è´¥: {str(e)}')
                
                mov_path = os.path.join(video_dir, f"{safe_title}.mov")
                self._log(task_id, f"ğŸ“„ è¾“å‡ºè·¯å¾„: {mov_path}")
                
                # é˜¶æ®µ3: æ›´æ–°ä»»åŠ¡çŠ¶æ€
                self._log(task_id, "é˜¶æ®µ3: æ›´æ–°ä»»åŠ¡çŠ¶æ€")
                try:
                    self.redis.update_task_status(task_id, 'downloading', progress=0)
                    self._log(task_id, "âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: downloading")
                except Exception as e:
                    self._log(task_id, f"âŒ é˜¶æ®µ3å¤±è´¥: æ›´æ–°çŠ¶æ€é”™è¯¯ - {str(e)}")
                    raise Exception(f'æ›´æ–°çŠ¶æ€å¤±è´¥: {str(e)}')
                
                # é˜¶æ®µ4: è·å–Cookie
                self._log(task_id, "é˜¶æ®µ4: è·å–æŠ–éŸ³Cookie")
                try:
                    cookie_data = self.redis.get_cookie('douyin')
                    if cookie_data and 'cookie' in cookie_data:
                        self._log(task_id, f"âœ… Cookieå·²è·å– (é•¿åº¦: {len(cookie_data['cookie'])})")
                    else:
                        self._log(task_id, "âš ï¸  æœªæ‰¾åˆ°Cookieï¼Œå°†å°è¯•æ— Cookieä¸‹è½½")
                except Exception as e:
                    self._log(task_id, f"âŒ é˜¶æ®µ4å¤±è´¥: è·å–Cookieé”™è¯¯ - {str(e)}")
                    self._log(task_id, "   âš ï¸  å°†ç»§ç»­å°è¯•æ— Cookieä¸‹è½½")
                    cookie_data = None
                
                # é˜¶æ®µ5: è°ƒç”¨æŠ–éŸ³ä¸‹è½½
                self._log(task_id, "é˜¶æ®µ5: è°ƒç”¨æŠ–éŸ³ä¸‹è½½")
                
                # ä½¿ç”¨video_scraperè§£ææŠ–éŸ³è§†é¢‘ä¿¡æ¯
                try:
                    headers = self.headers.copy()
                    if cookie_data and 'cookie' in cookie_data:
                        headers['Cookie'] = cookie_data['cookie']
                        self._log(task_id, "âœ… ä½¿ç”¨Cookieè¿›è¡Œè§£æ")
                    
                    video_info = self.scraper.scrape_video(url, cookie_data)
                    
                    if not video_info or 'video_url' not in video_info or not video_info['video_url']:
                        self._log(task_id, "âŒ æ— æ³•è·å–æŠ–éŸ³è§†é¢‘ä¸‹è½½é“¾æ¥")
                        raise Exception('æ— æ³•è·å–æŠ–éŸ³è§†é¢‘ä¸‹è½½é“¾æ¥')
                    
                    video_url = video_info['video_url']
                    self._log(task_id, f"âœ… æˆåŠŸè·å–è§†é¢‘ä¸‹è½½é“¾æ¥: {video_url[:100]}...")
                    
                    # ç›´æ¥ä¸‹è½½è§†é¢‘æ–‡ä»¶
                    self._log(task_id, "ğŸ“¥ å¼€å§‹ä¸‹è½½è§†é¢‘æ–‡ä»¶...")
                    temp_file = os.path.join(video_dir, f"{safe_title}.mp4")
                    response = requests.get(video_url, headers=headers, timeout=600, stream=True)  # 10åˆ†é’Ÿè¶…æ—¶
                    response.raise_for_status()
                    
                    # ä¿å­˜è§†é¢‘æ–‡ä»¶
                    with open(temp_file, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            f.write(chunk)
                    
                    file_size = os.path.getsize(temp_file)
                    self._log(task_id, f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆï¼Œæ–‡ä»¶å¤§å°: {file_size} bytes ({file_size / 1024 / 1024:.2f} MB)")
                    
                    # è½¬ç ä¸ºmovæ ¼å¼
                    self._log(task_id, "é˜¶æ®µ6: è½¬ç ä¸ºmovæ ¼å¼")
                    self.redis.update_task_status(task_id, 'transcoding', progress=0)
                    self._log(task_id, "âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: transcoding")
                    success, message = self.transcoder.transcode_video(temp_file, mov_path, task_id)
                    
                    if success:
                        os.remove(temp_file)
                        self.redis.update_task_status(task_id, 'completed', progress=100, save_path=mov_path)
                        self._log(task_id, f"âœ… ä¸‹è½½ä»»åŠ¡å®Œæˆ: {mov_path}")
                        return True, 'ä¸‹è½½æˆåŠŸ'
                    else:
                        self._log(task_id, f"âŒ é˜¶æ®µ6å¤±è´¥: è½¬ç å¤±è´¥ - {message}")
                        error_msg = f'è½¬ç å¤±è´¥: {message}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                        self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                        return False, error_msg
                        
                except Exception as e:
                    self._log(task_id, f"âŒ é˜¶æ®µ5å¤±è´¥: æŠ–éŸ³ä¸‹è½½é”™è¯¯ - {str(e)}")
                    import traceback
                    traceback.print_exc()
                    video_url = video_info.get('video_url', 'N/A') if 'video_info' in locals() else 'N/A'
                    error_msg = f'æŠ–éŸ³ä¸‹è½½å¤±è´¥: {str(e)}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                    self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                    return False, error_msg
            
            # å…¶ä»–å¹³å°ä½¿ç”¨åŸæœ‰çš„parseré€»è¾‘
            # é˜¶æ®µ2: è§£æè§†é¢‘ä¿¡æ¯
            print(f"ğŸ” é˜¶æ®µ2: è§£æè§†é¢‘ä¿¡æ¯")
            try:
                video_info = self.parser.parse_video_info(url)
                print(f"âœ… è§†é¢‘ä¿¡æ¯è§£ææˆåŠŸ")
                print(f"   æ ‡é¢˜: {video_info.get('title', 'N/A')}")
                print(f"   å¹³å°: {video_info.get('platform', 'N/A')}")
            except Exception as e:
                print(f"âŒ é˜¶æ®µ2å¤±è´¥: è§†é¢‘ä¿¡æ¯è§£æé”™è¯¯")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                import traceback
                traceback.print_exc()
                raise Exception(f'è§†é¢‘ä¿¡æ¯è§£æå¤±è´¥: {str(e)}')
            
            # é˜¶æ®µ3: æ›´æ–°ä»»åŠ¡çŠ¶æ€
            print(f"ğŸ“Š é˜¶æ®µ3: æ›´æ–°ä»»åŠ¡çŠ¶æ€")
            try:
                self.redis.update_task_status(
                    task_id, 
                    'downloading',
                    progress=0
                )
                print(f"âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: downloading")
            except Exception as e:
                print(f"âŒ é˜¶æ®µ3å¤±è´¥: æ›´æ–°çŠ¶æ€é”™è¯¯")
                print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                raise Exception(f'æ›´æ–°çŠ¶æ€å¤±è´¥: {str(e)}')
            
            platform = video_info['platform']
            cookie_data = self.redis.get_cookie(platform)
            
            title = video_info['title']
            video_url = video_info['video_url']
            audio_url = video_info.get('audio_url')
            
            import os
            platform_dir = os.path.join(storage_path, platform)
            os.makedirs(platform_dir, exist_ok=True)
            
            # ä½¿ç”¨å®‰å…¨æ–‡ä»¶ååˆ›å»ºç›®å½•
            safe_title = self._get_safe_filename(title)
            video_dir = os.path.join(platform_dir, safe_title)
            os.makedirs(video_dir, exist_ok=True)
            
            mov_filename = f"{safe_title}.mov"
            mov_path = os.path.join(video_dir, mov_filename)
            
            if platform == 'douyin':
                return self._download_douyin_with_ytdlp(url, task_id, mov_path)
            
            video_filename = f"{safe_title}.mp4"
            video_path = os.path.join(video_dir, video_filename)
            
            headers = self.headers.copy()
            headers['Referer'] = 'https://www.bilibili.com'
            headers['Origin'] = 'https://www.bilibili.com'
            headers['Accept'] = '*/*'
            headers['Accept-Language'] = 'zh-CN,zh;q=0.9,en;q=0.8'
            headers['Accept-Encoding'] = 'gzip, deflate, br'
            headers['Connection'] = 'keep-alive'
            headers['Sec-Fetch-Dest'] = 'empty'
            headers['Sec-Fetch-Mode'] = 'cors'
            headers['Sec-Fetch-Site'] = 'same-site'
            if cookie_data:
                if platform == 'bilibili' and 'SESSDATA' in cookie_data:
                    headers['Cookie'] = f'SESSDATA={cookie_data["SESSDATA"]}'
                elif platform in ['douyin', 'toutiao'] and 'cookie' in cookie_data:
                    headers['Cookie'] = cookie_data['cookie']
            
            if audio_url:
                audio_filename = f"{safe_title}_audio.m4a"
                audio_path = os.path.join(video_dir, audio_filename)
                
                response_audio = requests.get(audio_url, headers=headers, stream=True, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
                response_audio.raise_for_status()
                
                total_audio_size = int(response_audio.headers.get('content-length', 0))
                downloaded_audio_size = 0
                
                with open(audio_path, 'wb') as f:
                    for chunk in response_audio.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_audio_size += len(chunk)
                
                response = requests.get(video_url, headers=headers, stream=True, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
                response.raise_for_status()
                
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                start_time = time.time()
                last_update_time = start_time
                
                with open(video_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            current_time = time.time()
                            if current_time - last_update_time >= 1:
                                elapsed_time = current_time - start_time
                                if elapsed_time > 0:
                                    speed = downloaded_size / elapsed_time
                                    speed_str = self._format_speed(speed)
                                    self.redis.update_task_download_speed(task_id, speed_str)
                                last_update_time = current_time
                            if total_size > 0:
                                progress = int(downloaded_size / total_size * 50)
                                self.redis.update_task_status(task_id, 'downloading', progress=progress)
                
                import subprocess
                merged_filename = f"{safe_title}_merged.mp4"
                merged_path = os.path.join(video_dir, merged_filename)
                
                cmd = [
                    'ffmpeg',
                    '-i', video_path,
                    '-i', audio_path,
                    '-c:v', 'copy',
                    '-c:a', 'aac',
                    '-y',
                    merged_path
                ]
                
                process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                process.wait()
                
                if os.path.exists(merged_path):
                    os.remove(video_path)
                    os.remove(audio_path)
                    os.rename(merged_path, video_path)
            else:
                response = requests.get(video_url, headers=headers, stream=True, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
                response.raise_for_status()
                
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                start_time = time.time()
                last_update_time = start_time
                
                with open(video_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            current_time = time.time()
                            if current_time - last_update_time >= 1:
                                elapsed_time = current_time - start_time
                                if elapsed_time > 0:
                                    speed = downloaded_size / elapsed_time
                                    speed_str = self._format_speed(speed)
                                    self.redis.update_task_download_speed(task_id, speed_str)
                                last_update_time = current_time
                            if total_size > 0:
                                progress = int(downloaded_size / total_size * 100)
                                self.redis.update_task_status(task_id, 'downloading', progress=progress)
            
            if os.path.exists(video_path):
                self.redis.update_task_status(task_id, 'transcoding', progress=0)
                success, message = self.transcoder.transcode_video(video_path, mov_path, task_id)
                
                if success:
                    os.remove(video_path)
                    self.redis.update_task_status(task_id, 'completed', progress=100, save_path=mov_path)
                    return True, 'ä¸‹è½½æˆåŠŸ'
                else:
                    # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
                    error_msg = f'è½¬ç å¤±è´¥: {message}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                    self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                    return False, error_msg
            else:
                # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
                error_msg = f'ä¸‹è½½å¤±è´¥: è§†é¢‘æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½æ˜¯ç½‘é¡µæœªè§£æå‡ºè§†é¢‘ä¸‹è½½åœ°å€\n\nè§£æçš„è§†é¢‘URL: {video_url}'
                self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
                return False, error_msg
            
        except Exception as e:
            # æ·»åŠ è§†é¢‘URLåˆ°é”™è¯¯ä¿¡æ¯
            error_msg = f'ä¸‹è½½å¤±è´¥: {str(e)}\n\nè§£æçš„è§†é¢‘URL: {video_url}'
            self.redis.update_task_status(task_id, 'failed', error_message=error_msg)
            return False, error_msg